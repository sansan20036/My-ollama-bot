# app/services/chat_service.py
import logging
import os
import re
from typing import AsyncGenerator, List, Dict, Any
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

from app.core.config import settings
from app.services.vector_store import VectorStoreService
from app.services.cache_service import SemanticCacheService

logger = logging.getLogger(__name__)


class ChatService:
    def __init__(self):
        os.environ["NO_PROXY"] = "*"
        os.environ["no_proxy"] = "*"

        self.vector_store = VectorStoreService.get_instance()
        self.cache = SemanticCacheService.get_instance()
        self.upload_dir = os.path.join(os.getcwd(), "uploads")

        # âœ… å»ºè­°ä½¿ç”¨ 8b æ¨¡å‹ä»¥ç²å¾—æœ€ä½³é€Ÿåº¦èˆ‡é€šç”¨æ€§
        target_model = "gpt-oss:20b"

        logger.info(f"ğŸ”¥ åˆå§‹åŒ–å…¨èƒ½æ–‡ä»¶èŠå¤©æœå‹™: {target_model}")

        self.llm = ChatOllama(
            base_url=settings.OLLAMA_BASE_URL,
            model=target_model,
            temperature=0.1,
            keep_alive="1h",
            num_ctx=8192,
            num_predict=4096
        )

    def _get_valid_files(self) -> list:
        if not os.path.exists(self.upload_dir): return []
        return [f for f in os.listdir(self.upload_dir) if
                os.path.isfile(os.path.join(self.upload_dir, f)) and not f.startswith("~")]

    def _get_sorted_file_list(self, files: list) -> str:
        if not files: return "(ç„¡æª”æ¡ˆ)"
        return "\n".join([f"{i + 1}. {f}" for i, f in enumerate(files)])

    def _num_to_chinese(self, num_str):
        try:
            n = int(num_str)
            units = ["", "å", "ç™¾"]
            chars = ["é›¶", "ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹"]
            if n == 0: return chars[0]
            result = ""
            s = str(n)[::-1]
            for i, d in enumerate(s):
                d = int(d)
                if i >= len(units): break
                if d != 0:
                    if i == 1 and d == 1 and len(s) == 2:
                        result = units[i] + result
                    else:
                        result = chars[d] + units[i] + result
                else:
                    if result and result[0] != chars[0]: result = chars[0] + result
            return result
        except:
            return num_str

    def _chinese_to_num(self, cn_str):
        if cn_str.isdigit(): return int(cn_str)
        cn_map = {'é›¶': 0, 'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
                  'ç™¾': 100}
        try:
            if cn_str.startswith("å"):
                return 10 + cn_map.get(cn_str[1], 0) if len(cn_str) > 1 else 10
            elif len(cn_str) == 2 and cn_str[1] == "å":
                return cn_map[cn_str[0]] * 10
            elif len(cn_str) == 3 and cn_str[1] == "å":
                return cn_map[cn_str[0]] * 10 + cn_map[cn_str[2]]
            elif "ç™¾" in cn_str:
                return 100
            else:
                return cn_map.get(cn_str, 0)
        except:
            return 0

    async def _smart_query_rewrite(self, user_query: str) -> str:
        """
        ğŸ”¥ è¬ç”¨å‹æ„åœ–é åˆ¤ (Universal Intent Prediction)
        """
        rewrite_prompt = ChatPromptTemplate.from_template(
            """ä½ æ˜¯é«˜éšæ–‡ä»¶æª¢ç´¢å°ˆå®¶ã€‚ä½¿ç”¨è€…çš„å•é¡Œæ˜¯ï¼šã€Œ{query}ã€ã€‚
            ä½ çš„ä»»å‹™æ˜¯åˆ†æé€™å€‹å•é¡Œï¼Œä¸¦é æ¸¬ã€Œåœ¨ç›®æ¨™æ–‡ä»¶ä¸­ï¼Œé€™æ®µå…§å®¹å¯èƒ½åŒ…å«å“ªäº›é—œéµå­—æˆ–è¡“èªã€ã€‚
            è«‹å¿½ç•¥æ–‡ä»¶çš„å…·é«”é¡å‹ï¼Œç›´æ¥æ ¹æ“šå¸¸è­˜é€²è¡Œè¯æƒ³ã€‚

            è«‹è¼¸å‡º 5~10 å€‹ã€Œæœ€èƒ½ç²¾æº–å‘½ä¸­æ–‡ä»¶å…§å®¹ã€çš„æœå°‹é—œéµå­—ã€‚
            ç›´æ¥è¼¸å‡ºé—œéµå­—ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¸è¦æœ‰è§£é‡‹ã€‚

            ç¯„ä¾‹ï¼š
            (å•ï¼šè€é—†ä¸çµ¦è³‡é£è²») -> å‹å‹•åŸºæº–æ³• çµ‚æ­¢å¥‘ç´„ ç¬¬17æ¢ è³‡é£è²» ç½°å‰‡
            (å•ï¼šDockeré€£ä¸ä¸Š) -> Connection refused, port mapping, ç¶²è·¯è¨­å®š, é˜²ç«ç‰†

            ç¾åœ¨è«‹è¼¸å‡ºé—œéµå­—ï¼š"""
        )

        chain = rewrite_prompt | self.llm | StrOutputParser()
        print(f"ğŸ¤” AI æ­£åœ¨é€²è¡Œè¬ç”¨é—œéµå­—è¯æƒ³...")
        refined_query = await chain.ainvoke({"query": user_query})
        clean_query = refined_query.replace("\n", " ").strip()
        print(f"âœ¨ AI è¯æƒ³é—œéµå­—: {clean_query}")
        return clean_query

    async def process_query(self, query: str, history: list) -> AsyncGenerator[str, None]:
        yield "ğŸ§  **AI æ­£åœ¨åˆ†ææ–‡ä»¶å…§å®¹...**\n\n"

        real_query = query
        valid_files = self._get_valid_files()
        file_count = len(valid_files)
        file_list_str = self._get_sorted_file_list(valid_files)

        if file_count == 0:
            yield "âš ï¸ è³‡æ–™åº«ç‚ºç©ºã€‚è«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚"
            return

        # =========================================================
        # 1. ç¬¬ä¸€è¼ªï¼šé€šç”¨æª¢ç´¢
        # =========================================================
        ai_keywords = await self._smart_query_rewrite(real_query)
        search_query = f"{real_query} {ai_keywords}"

        matches = re.findall(r'ç¬¬\s*(\d{1,3})\s*[æ¢ç« ç¯€]', real_query)
        if matches:
            for m in matches:
                cn_num = self._num_to_chinese(m)
                search_query += f" ç¬¬{cn_num}æ¢ ç¬¬{cn_num}ç« "

        # å‘¼å«æœå°‹çš„åœ°æ–¹
        print(f"ğŸš€ åŸ·è¡Œæª¢ç´¢: {search_query}") # é€™è£¡å‘¼å«äº†ä¸Šé¢çš„é‚£å€‹ search æ–¹æ³•
        docs = self.vector_store.search(search_query, k=15) # å›å‚³æœ€ç›¸é—œçš„ 15 ç­†æ–‡ä»¶ (docs)

        # =========================================================
        # ğŸ”¥ æ–°å¢ï¼šç‹™æ“Šæ¨¡å¼ (Sniper Mode)
        # å¦‚æœä½¿ç”¨è€…æ˜ç¢ºèªªäº†ã€Œç¬¬Xæ¢ã€ï¼Œæˆ‘å€‘å°±å¼·åˆ¶å»è³‡æ–™åº«æŒ–å‡ºä¾†ï¼Œä¸çœ‹é‹æ°£
        # =========================================================
        if matches:
            print(f"ğŸ¯ åµæ¸¬åˆ°æ˜ç¢ºæ¢è™Ÿ {matches}ï¼Œå•Ÿå‹•ç‹™æ“Šæ¨¡å¼...")
            # å»ºç«‹ç›®å‰å·²æŠ“åˆ°çš„ ID é›†åˆï¼Œé¿å…é‡è¤‡
            existing_ids = set()
            for d in docs:
                aid = d.metadata.get("article_id")
                if aid: existing_ids.add(str(aid))

            for m in matches:
                target_id = str(int(m))  # è½‰æˆå­—ä¸² ID (å¦‚ "80")

                # å¦‚æœå»£æ³›æœå°‹å·²ç¶“æŠ“åˆ°äº†ï¼Œå°±ä¸ç”¨å¿™äº†
                if target_id in existing_ids:
                    print(f"âœ… ç¬¬ {m} æ¢å·²åœ¨æœå°‹çµæœä¸­ï¼Œè·³éå¼·åˆ¶èª¿é–±ã€‚")
                    continue

                # å¦‚æœæ²’æŠ“åˆ°ï¼Œç™¼èµ·ç²¾æº–æœå°‹ (ä½¿ç”¨ filter å¦‚æœæ”¯æ´ï¼Œæˆ–å»£æœå¾Œéæ¿¾)
                print(f"ğŸ”« åŸ·è¡Œå¼·åˆ¶èª¿é–±ï¼šç¬¬ {m} æ¢...")
                sniper_query = f"ç¬¬{m}æ¢"

                # åˆ©ç”¨æˆ‘å€‘å‰›åœ¨ VectorStore å¯¦ä½œçš„ filter åŠŸèƒ½ (æœ€ç©©)
                # æ³¨æ„ï¼šé€™éœ€è¦æ‚¨çš„ vector_store.search æ”¯æ´ filter åƒæ•¸
                # å¦‚æœä¸æ”¯æ´ï¼Œæˆ‘å€‘ç”¨ k=50 æš´åŠ›æœ
                sniper_docs = self.vector_store.search(sniper_query, k=50)

                found_target = False
                for d in sniper_docs:
                    fetched_id = str(d.metadata.get("article_id", ""))
                    if fetched_id == target_id:
                        d.page_content = f"ã€ä½¿ç”¨è€…æŒ‡å®šèª¿é–±ï¼šç¬¬{m}æ¢ã€‘\n{d.page_content}"
                        # ğŸ”¥ å¼·åˆ¶æ’å…¥åˆ°æœ€å‰é¢ (ç½®é ‚)
                        docs.insert(0, d)
                        existing_ids.add(target_id)
                        print(f"âœ… ç‹™æ“ŠæˆåŠŸï¼šå·²å¼·åˆ¶è¼‰å…¥ ç¬¬ {m} æ¢")
                        found_target = True
                        break

                if not found_target:
                    print(f"âš ï¸ ç‹™æ“Šå¤±æ•—ï¼šè³‡æ–™åº«ä¸­æ‰¾ä¸åˆ° ID={target_id} çš„æ¢æ–‡")

        # =========================================================
        # 2. ç¬¬äºŒè¼ªï¼šå½ˆæ€§è£œå®Œ (Adaptive Auto-Completion)
        # =========================================================
        existing_ids = set()
        has_structured_data = False

        for doc in docs:
            aid = doc.metadata.get("article_id")
            if aid:
                existing_ids.add(str(aid))
                has_structured_data = True

        if has_structured_data:
            print("ğŸ•µï¸â€â™‚ï¸ åµæ¸¬åˆ°çµæ§‹åŒ–è³‡æ–™ï¼Œå˜—è©¦åˆ†æå¼•ç”¨é—œä¿‚...")
            referenced_ids = set()
            for doc in docs:
                content = doc.page_content
                refs = re.findall(r'ç¬¬\s*([0-9]+|[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+)\s*æ¢', content)
                for ref in refs:
                    if ref not in existing_ids and ref not in ["ä¸€", "äºŒ"]:
                        referenced_ids.add(ref)

            if referenced_ids:
                target_refs = list(referenced_ids)[:5]
                print(f"ğŸ”— ç™¼ç¾å¼•ç”¨ï¼Œå˜—è©¦è£œå®Œ: {target_refs}")
                yield f"ğŸ”— **æ­£åœ¨èª¿é–±ç›¸é—œç« ç¯€ ({len(target_refs)} ç­†)...**\n\n"

                for ref_art in target_refs:
                    target_id = self._chinese_to_num(ref_art)
                    if target_id == 0: continue

                    fetch_query = f"ç¬¬{ref_art}æ¢"
                    supplementary_docs = self.vector_store.search(fetch_query, k=50)

                    for d in supplementary_docs:
                        fetched_id = str(d.metadata.get("article_id", ""))
                        if fetched_id == str(target_id) and fetched_id not in existing_ids:
                            d.page_content = f"ã€ç³»çµ±è‡ªå‹•è£œå®Œå¼•ç”¨ï¼šç¬¬{ref_art}æ¢ã€‘\n{d.page_content}"
                            docs.append(d)
                            existing_ids.add(fetched_id)
                            print(f"âœ… æˆåŠŸè£œå®Œ ID: {fetched_id}")
                            break

        # =========================================================
        # 3. æ’åºèˆ‡ Context
        # =========================================================
        def final_rank(doc):
            score = 0
            content = doc.page_content
            if "ã€ä½¿ç”¨è€…æŒ‡å®šèª¿é–±" in content: score += 2000  # æœ€é«˜æ¬Šé‡
            if "ã€ç³»çµ±è‡ªå‹•è£œå®Œ" in content: score += 50
            if doc.metadata.get("type") == "file_summary": score += 1000
            if query in content: score += 100
            return score

        docs.sort(key=final_rank, reverse=True)

        final_context_list = []
        for doc in docs[:10]:
            source = doc.metadata.get("source", "unknown")
            page = doc.metadata.get("page", "")
            article_id = doc.metadata.get("article_id", "")

            label = ""
            if article_id:
                label = f" | ç¬¬ {article_id} æ¢"
            elif page:
                label = f" | Page {page}"

            if doc.metadata.get("type") == "file_summary":
                prefix = f"ğŸ”¥ã€å…¨åŸŸæ‘˜è¦ï¼š{source}ã€‘"
            else:
                prefix = f"ã€ä¾†æºï¼š{source}{label}ã€‘"

            final_context_list.append(f"{prefix}\n{doc.page_content}")

        final_context = "\n\n".join(final_context_list) if final_context_list else "ç„¡å…·é«”å…§å®¹ã€‚"

        # Debug View
        print("\n======== ğŸ•µï¸â€â™‚ï¸ Universal RAG Context ========")
        print(f"æœ€çµ‚ Context ç­†æ•¸: {len(final_context_list)}")
        print(final_context[:300] + "...")
        print("==========================================\n")

        # =========================================================
        # 4. ç”Ÿæˆå›æ‡‰
        # =========================================================
        yield "âš¡ **AI æ­£åœ¨ç”Ÿæˆè§£ç­”...**\n\n"

        history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in history[-2:]]) if history else "(ç„¡æ­·å²ç´€éŒ„)"

        template_str = """You are a professional, multilingual AI legal assistant.

                [SYSTEM STATUS] Uploaded Files: {file_count}

                [IMPORTANT LEGAL LOGIC RULES]
                Please strictly follow these logical connections when answering:
                1. **Article 11 (Economic Layoff/Incompetence)**:
                   - Represents "Layoff" (è³‡é£).
                   - **MUST** provide advance notice (Article 16).
                   - **MUST** pay severance pay (Article 17).
                2. **Article 12 (Disciplinary Dismissal)**:
                   - Represents "Firing" (é–‹é™¤/æ‡²æˆ’æ€§è§£åƒ±).
                   - **NO** advance notice required.
                   - **NO** severance pay required.
                3. **Double Negative Check**:
                   - "é...ä¸å¾—..." means "Unless..., cannot...". It does NOT mean "No notice needed".

                [RETRIEVED KNOWLEDGE]
                The following content is retrieved from the database (mostly in Traditional Chinese).
                Use this knowledge to answer the user's question.
                {context}

                [CHAT HISTORY] {history}

                [USER QUESTION] {question}

                [âš ï¸ MANDATORY LANGUAGE PROTOCOL âš ï¸]
                You must strictly follow these rules to determine the output language:

                1. **AUTO-DETECT**: Detect the language used in the [USER QUESTION].
                2. **MATCH LANGUAGE**: Your entire response MUST be in the **SAME language** as the [USER QUESTION].
                   - If user asks in **Japanese**, answer in **Japanese**.
                   - If user asks in **English**, answer in **English**.
                   - If user asks in **Chinese** (Simplified/Traditional), answer in **Traditional Chinese**.
                3. **TRANSLATION REQUIRED**: 
                   - The [RETRIEVED KNOWLEDGE] is in Chinese. 
                   - You must **READ** the Chinese context, **UNDERSTAND** it, and then **TRANSLATE & EXPLAIN** it in the user's target language.
                   - **DO NOT** output Traditional Chinese if the user asked in English or Japanese (unless it's for specific proper nouns).

                [RESPONSE FORMAT]
                - Be precise and helpful.
                - If the document mentions specific articles (e.g., ç¬¬12æ¢), cite them in the target language (e.g., Article 12, ç¬¬12æ¡).
                
                [CRITICAL READING RULES]
        1. **NO SIMPLIFICATION**: When citation involves numbers, money, or days, DO NOT output a single number if the document lists a range or conditions. (e.g., if text says "10 to 30 days", do not say "30 days").
        2. **FULL LISTING**: Always list out all the tiered conditions found in the text.
        3. **FACTUAL ACCURACY**: Your answer must perfectly match the [RETRIEVED KNOWLEDGE]. Do not use your own training data if it conflicts with the file.
                """

        prompt = ChatPromptTemplate.from_template(template_str)
        chain = (
                {
                    "context": lambda x: final_context,
                    "question": RunnablePassthrough(),
                    "history": lambda x: history_text,
                    "file_list_str": lambda x: file_list_str,
                    "file_count": lambda x: str(file_count)
                }
                | prompt
                | self.llm
                | StrOutputParser()
        )

        try:
            async for chunk in chain.astream(real_query):
                clean_chunk = (chunk.replace("<br>", "\n").replace("<b>", "**").replace("</b>", "**"))
                yield clean_chunk
        except Exception as e:
            logger.error(f"Chat Error: {e}")
            yield f"\n\nâš ï¸ ç™¼ç”ŸéŒ¯èª¤: {str(e)}"