import logging
import os
import shutil
from typing import List, Optional, Dict, Any

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document

from app.core.config import settings
from app.utils.smart_parser import SmartFileParser  # ç¢ºä¿é€™æ”¯ç¨‹å¼å·²å­˜åœ¨

logger = logging.getLogger(__name__)


class VectorStoreService:
    _instance = None

    def __init__(self):
        # åˆå§‹åŒ– Embedding æ¨¡å‹
        # ä½¿ç”¨ HuggingFace æ¨¡å‹å°‡æ–‡å­—è½‰ç‚ºå‘é‡
        self.embeddings = HuggingFaceEmbeddings(model_name=settings.EMBEDDING_MODEL)
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ– ChromaDB é€£ç·š"""
        self.db = Chroma(
            persist_directory=settings.CHROMA_DB_DIR,
            embedding_function=self.embeddings
        )

    @classmethod
    def get_instance(cls):
        """Singleton æ¨¡å¼ï¼Œç¢ºä¿å…¨åŸŸåªæœ‰ä¸€å€‹å¯¦ä¾‹"""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def add_documents(self, docs: List[Document]):
        """
        å°‡æ–‡ä»¶å­˜å…¥å‘é‡è³‡æ–™åº« (åŒæ­¥æ–¹æ³•)
        """
        if docs:
            try:
                # ChromaDB çš„ add_documents æœƒè‡ªå‹•è™•ç† ID å’Œå‘é‡åŒ–
                self.db.add_documents(docs)
                logger.info(f"ğŸ“¥ æˆåŠŸå­˜å…¥ {len(docs)} ç­†å‘é‡è³‡æ–™ç‰‡æ®µ")
            except Exception as e:
                logger.error(f"âŒ å­˜å…¥å‘é‡è³‡æ–™åº«å¤±æ•—: {e}")
                raise e

    async def process_file(self, file_path: str):
        """
        ğŸ”¥ æ ¸å¿ƒæµç¨‹ï¼šè®€å– -> æ™ºæ…§è§£æ -> å„²å­˜
        """
        try:
            # é¿å…å¾ªç’°å¼•ç”¨ï¼Œåœ¨å‡½å¼å…§ import
            from app.services.file_service import FileLoaderFactory

            filename = os.path.basename(file_path)

            # 1. è®€å–åŸå§‹æ–‡å­— (ä½¿ç”¨ FileLoaderFactory)
            loader = FileLoaderFactory.get_loader(file_path, filename)
            text_content = loader.extract_text()

            if not text_content:
                logger.warning(f"âš ï¸ æª”æ¡ˆ {filename} ç„¡å…§å®¹æˆ–ç„¡æ³•è®€å–ï¼Œè·³éè™•ç†")
                return

            # 2. ğŸ”¥ å•Ÿå‹• SmartFileParser é€²è¡Œçµæ§‹åŒ–è§£æ
            logger.info(f"ğŸ§  å•Ÿå‹• SmartFileParser è§£ææª”æ¡ˆ: {filename}")
            parser = SmartFileParser()

            # é€™æœƒå›å‚³ä¸€ç³»åˆ—å¸¶æœ‰è±å¯Œ metadata (å¦‚ article_id, type) çš„ Document ç‰©ä»¶
            docs = parser.parse(text_content, filename)

            # 3. å­˜å…¥è³‡æ–™åº«
            if docs:
                self.add_documents(docs)
                logger.info(f"âœ… æª”æ¡ˆ '{filename}' è™•ç†å®Œæˆï¼Œå…±å­˜å…¥ {len(docs)} ç­†çµæ§‹åŒ–è³‡æ–™")
            else:
                logger.warning(f"âš ï¸ æª”æ¡ˆ '{filename}' è§£æå¾Œç„¡æœ‰æ•ˆè³‡æ–™ç‰‡æ®µ")

        except Exception as e:
            logger.error(f"âŒ è™•ç†æª”æ¡ˆå¤±æ•— {file_path}: {e}")
            raise e
    # å®šç¾©æœå°‹å‹•ä½œçš„åœ°æ–¹
    def search(self, query: str, k: int = 4, filter: Optional[Dict[str, Any]] = None):
        """
        åŸ·è¡Œå‘é‡ç›¸ä¼¼åº¦æœå°‹
        Args:
            query: æœå°‹é—œéµå­—
            k: å›å‚³ç­†æ•¸
            filter: Metadata éæ¿¾æ¢ä»¶ (ä¾‹å¦‚ {"article_id": "12"})
        """
        if filter:
            # å¦‚æœæœ‰æŒ‡å®š filterï¼Œä½¿ç”¨å¸¶éæ¿¾çš„æœå°‹
            return self.db.similarity_search(query, k=k, filter=filter)
        else:
            # ä¸€èˆ¬æœå°‹
            return self.db.similarity_search(query, k=k)

    def list_sources(self):
        """
        åˆ—å‡ºç›®å‰è³‡æ–™åº«ä¸­æ‰€æœ‰ä¸é‡è¤‡çš„æª”æ¡ˆåç¨±
        """
        try:
            # åªæŠ“å– metadataï¼Œä¸æŠ“ embedding å‘é‡ï¼Œé€Ÿåº¦å¿«
            data = self.db.get(include=['metadatas'])
            metadatas = data.get("metadatas", [])

            sources = set()
            if metadatas:
                for m in metadatas:
                    if m and "source" in m:
                        sources.add(m["source"])

            return sorted(list(sources))
        except Exception as e:
            logger.error(f"Error listing sources: {e}")
            return []

    def delete_file(self, filename: str):
        """åˆªé™¤æŒ‡å®šæª”æ¡ˆçš„æ‰€æœ‰å‘é‡è³‡æ–™"""
        try:
            # 1. æ‰¾å‡ºè©²æª”æ¡ˆå°æ‡‰çš„æ‰€æœ‰ ID
            data = self.db.get(where={"source": filename})
            ids = data.get("ids", [])

            if ids:
                # 2. æ ¹æ“š ID åˆªé™¤
                self.db.delete(ids)
                logger.info(f"ğŸ—‘ï¸ å·²åˆªé™¤æª”æ¡ˆ '{filename}'ï¼Œå…±ç§»é™¤ {len(ids)} ç­†å‘é‡ç‰‡æ®µ")
                return True
            else:
                logger.warning(f"âš ï¸ æ‰¾ä¸åˆ°æª”æ¡ˆ '{filename}' çš„è³‡æ–™")
                return False
        except Exception as e:
            logger.error(f"åˆªé™¤æª”æ¡ˆå¤±æ•—: {e}")
            raise e

    def get_file_content(self, filename: str) -> str:
        """è®€å–æŒ‡å®šæª”æ¡ˆçš„å®Œæ•´å…§å®¹ (å°‡åˆ‡ç‰‡ç¸«åˆï¼Œç”¨æ–¼å‰ç«¯é è¦½)"""
        try:
            # æ ¹æ“š source æŠ“å–æ‰€æœ‰ç‰‡æ®µ
            data = self.db.get(where={"source": filename})
            documents = data.get("documents", [])
            metadatas = data.get("metadatas", [])

            if not documents:
                return "ç„¡å…§å®¹æˆ–æ˜¯åœ–ç‰‡æª”æ¡ˆ (æœªå„²å­˜ç´”æ–‡å­—)ã€‚"

            # å˜—è©¦æ ¹æ“š 'chunk_index' æˆ– 'article_id' æ’åºï¼Œè®“ç¸«åˆå¾Œçš„æ–‡å­—é †åºæ­£ç¢º
            combined = zip(documents, metadatas)

            # å„ªå…ˆå˜—è©¦ç”¨ metadata è£¡çš„ chunk_id æ’åºï¼Œå¦‚æœæ²’æœ‰å°±ä¿æŒåŸæ¨£
            try:
                sorted_combined = sorted(combined, key=lambda x: x[1].get('chunk_id', 0) if x[1] else 0)
                sorted_docs = [doc for doc, meta in sorted_combined]
            except:
                sorted_docs = documents

            return "\n\n-------------------\n\n".join(sorted_docs)
        except Exception as e:
            logger.error(f"è®€å–æª”æ¡ˆå…§å®¹å¤±æ•—: {e}")
            return f"è®€å–éŒ¯èª¤: {str(e)}"

    def reset(self):
        """ğŸ”¥ å¼·åˆ¶æ¸…ç©ºè³‡æ–™åº« (Purge System)"""
        try:
            # 1. å˜—è©¦å¾ Chroma åˆªé™¤æ‰€æœ‰è³‡æ–™
            all_ids = self.db.get()['ids']
            if all_ids:
                # Chroma é™åˆ¶ä¸€æ¬¡åˆªé™¤æ•¸é‡ï¼Œåˆ†æ‰¹åˆªé™¤è¼ƒå®‰å…¨
                batch_size = 5000
                for i in range(0, len(all_ids), batch_size):
                    batch_ids = all_ids[i:i + batch_size]
                    self.db.delete(batch_ids)
                logger.info(f"ğŸ—‘ï¸ å·²å¾ Chroma åˆªé™¤ {len(all_ids)} ç­†è³‡æ–™")

            # 2. é‡æ–°åˆå§‹åŒ–
            self.db = None
            self._init_db()
            logger.info("âœ… è³‡æ–™åº«é‡ç½®å®Œæˆ")

        except Exception as e:
            logger.error(f"Reset failed: {e}")