from langchain_ollama import ChatOllama

OLLAMA_HOST = "http://git.tedpc.com.tw:11434/"

# é€™æ˜¯ Ollama çš„ API æ¥å£ï¼Œç”¨ä¾†åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
import requests

try:
    response = requests.get(f"{OLLAMA_HOST}/api/tags")
    if response.status_code == 200:
        models = response.json().get('models', [])
        print("====== ä¼ºæœå™¨ä¸Šå¯ç”¨çš„æ¨¡å‹ ======")
        for m in models:
            print(f"ğŸ“¦ {m['name']}")
            # é¡¯ç¤ºè©³ç´°è³‡è¨Š (å¦‚å¤§å°)
            size_gb = m.get('size', 0) / (1024**3)
            print(f"   - å¤§å°: {size_gb:.2f} GB")
        print("================================")
    else:
        print(f"âŒ ç„¡æ³•é€£ç·šï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
except Exception as e:
    print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")