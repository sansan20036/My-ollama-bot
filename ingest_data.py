import ollama
import re  # ğŸŸ¢ å¼•å…¥æ­£è¦è¡¨ç¤ºå¼ç”¨æ–¼èªè¨€åµæ¸¬
from pypdf import PdfReader
from supabase import create_client
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. è¨­å®šé€£ç·šè³‡è¨Š (ä¿æŒä¸è®Š)
SUPABASE_URL = "https://abuxyukbleiauunrroks.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImFidXh5dWtibGVpYXV1bnJyb2tzIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjgyODM4NTUsImV4cCI6MjA4Mzg1OTg1NX0.w9g1xGbyHXGjCIj3wWl_0lkVojRzlkoQNTUEKZLRn8Q"
OLLAMA_HOST = "http://git.tedpc.com.tw:11434/"

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
ollama_client = ollama.Client(host=OLLAMA_HOST)

# 2. åˆ‡ç‰‡é‚è¼¯
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=150,
    chunk_overlap=80,
    separators=["\n\n", "\n", " "]
)

import re


def detect_language(text):
    # ğŸŸ¢ å„ªå…ˆæª¢æŸ¥æ˜¯å¦å«æœ‰æ—¥æ–‡å­—å…ƒ (å¹³å‡å \u3040-\u309f æˆ– ç‰‡å‡å \u30a0-\u30ff)
    if re.search(r"[\u3040-\u309f\u30a0-\u30ff]", text):
        return "Japanese"

    # ğŸŸ¢ æª¢æŸ¥æ˜¯å¦å«æœ‰éŸ“æ–‡å­—å…ƒ
    if re.search(r"[\uac00-\ud7af]", text):
        return "Korean"

    # ğŸŸ¢ æœ€å¾Œæ‰æª¢æŸ¥æ¼¢å­—ï¼Œç¢ºä¿ä¸æ˜¯æ—¥æ–‡å¾Œæ‰åˆ¤å®šç‚ºä¸­æ–‡
    if re.search(r"[\u4e00-\u9fff]", text):
        return "Chinese (Simplified)"

    if "English:" in text:
        return "English"

    return "Other"

def process_pdf_to_supabase(file_path):
    print(f"æ­£åœ¨åŸ·è¡Œã€Œè‡ªå‹•æ¨™ç±¤åŒ–ã€è™•ç†: {file_path}")
    reader = PdfReader(file_path)

    for i, page in enumerate(reader.pages):
        page_text = page.extract_text()
        if not page_text.strip(): continue

        chunks = text_splitter.split_text(page_text)
        print(f"ç¬¬ {i + 1} é åˆ‡åˆ†ç‚º {len(chunks)} å€‹ç‰‡æ®µ")

        for chunk in chunks:
            # ğŸŸ¢ åµæ¸¬ç•¶å‰ç‰‡æ®µçš„èªè¨€
            lang = detect_language(chunk)

            # å‘é‡åŒ–
            response = ollama_client.embeddings(model="nomic-embed-text", prompt=chunk)

            # ğŸŸ¢ å¯«å…¥è³‡æ–™åº«ï¼šåœ¨ metadata å¢åŠ  language æ¬„ä½
            supabase.table("documents").insert({
                "content": chunk,
                "embedding": response['embedding'],
                "metadata": {
                    "page": i + 1,
                    "language": lang  # çµ¦äºˆèªè¨€æ¨™ç±¤
                }
            }).execute()

    print("è³‡æ–™å·²æˆåŠŸåˆ†é¡å…¥åº«ï¼")


if __name__ == "__main__":
    process_pdf_to_supabase(r"C:\Users\sansa\PycharmProjects\Ollama\.venv\sample-multilingual-text.pdf")